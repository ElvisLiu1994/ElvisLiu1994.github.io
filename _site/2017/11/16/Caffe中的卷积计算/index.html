<!DOCTYPE html>
<html>

  <head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Caffe中的卷积计算 - Less Or More</title>

	<link rel="shortcut icon" href="/blog/styles/images/favicon.jpg">
	<link rel="icon" href="/blog/styles/images/favicon.jpg">

	<link rel="stylesheet" href="/blog/styles/css/index.css">
	<link rel="stylesheet" href="/blog/styles/css/fontawesome/css/font-awesome.min.css">
	<link rel="stylesheet" href="/blog/styles/css/syntax.css">
	<link rel="canonical" href="/blog/2017/11/16/Caffe%E4%B8%AD%E7%9A%84%E5%8D%B7%E7%A7%AF%E8%AE%A1%E7%AE%97/">
	<link rel="alternate" type="application/rss+xml" title="Less Or More" href="/blog/feed.xml">
	
	<!-- <meta name="keywords" content="Caffe中的卷积计算, Less Or More, "> -->
	<!-- <meta name="description" content=""> -->

	<script src="/blog/styles/js/jquery.min.js"></script>
	<!--[if lt IE 9]>
    	<script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
  	<![endif]-->
  	<!-- 统计网站访问量 -->
  <!-- 	<script>
		var _hmt = _hmt || [];
		(function() {
		  var hm = document.createElement("script");
		  hm.src = "//hm.baidu.com/hm.js?";
		  var s = document.getElementsByTagName("script")[0]; 
		  s.parentNode.insertBefore(hm, s);
		})();
	</script> -->
  	<style type="text/css">
	  	.docs-content{
	  		margin-bottom: 10px;
	  	}
  	</style>
</head>

  <body class="index">

    <header class="navbar navbar-inverse navbar-fixed-top docs-nav" role="banner">
  <div class="container">
    <div class="navbar-header">
      <a href="/" class="navbar-brand">
        <img src="/blog/styles/images/logo.jpg">
      </a>
    </div>
    <nav class="collapse navbar-collapse bs-navbar-collapse" role="navigation">
      <ul class="nav navbar-nav">    
        <li>
          <a href="/blog/">Home</a>
        </li> 
        <li>
          <a rel="nofollow" href="/blog/books">Books</a>
        </li>
        <li>
          <a rel="nofollow" target="_blank" href="https://github.com/elvisliu1994/">Github</a>
        </li>
      </ul>
    </nav>
  </div>
</header>
    <div class="docs-header" id="content">
  <div class="container">
	<h1>Talk is cheap<br/>show me the code.</h1>
  </div>
</div>
   <!--  
      
<div class="banner">
  <div class="container">
  	
    	<a href="/blog/categories/#Caffe-ref">Caffe</a>	/
    	<a href="/blog/tag/#卷积 计算-ref">卷积 计算</a>
    
  </div>
</div>

     -->

    <div class="container docs-container">
  <div class="row">
    <div class="col-md-3">
      <div class="sidebar hidden-print" role="complementary">
        <div id="navigation">
  <h1>目录</h1>
  <ul class="nav sidenav">
  </ul>
</div>

 
      </div>
    </div>
    <div class="col-md-9" role="main">
      <div class="panel docs-content">
        <div class="wrapper">
            <header class="post-header">
              <h1 class="post-title">Caffe中的卷积计算</h1>
              <div class="meta">Posted on <span class="postdate">Nov 16, 2017</span> By Elvis Liu
              </div>
              <br />
            </header>
            <article class="post-content">
              <ul id="markdown-toc">
  <li><a href="#caffe的卷积层" id="markdown-toc-caffe的卷积层">Caffe的卷积层</a></li>
  <li><a href="#1-最简单的实现-嵌套循环" id="markdown-toc-1-最简单的实现-嵌套循环">1. 最简单的实现: <em>嵌套循环</em></a></li>
  <li><a href="#2-caffe里面的计算方式" id="markdown-toc-2-caffe里面的计算方式">2. Caffe里面的计算方式</a></li>
  <li><a href="#3-im2col方法" id="markdown-toc-3-im2col方法">3. im2col方法</a></li>
  <li><a href="#4-举个例子" id="markdown-toc-4-举个例子">4. 举个例子</a></li>
  <li><a href="#参考" id="markdown-toc-参考"><em>参考</em></a></li>
</ul>

<h3 id="caffe的卷积层">Caffe的卷积层</h3>

<p>在第一次接触Caffe时，阅读了<code class="highlighter-rouge">lenet</code>的prototxt文件<code class="highlighter-rouge">caffe/example/mnist/lenet_train_test.prototxt</code>，该文件中描述了<code class="highlighter-rouge">lenet</code>网络各层的配置信息，其中对于卷积层的定义如下：</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>layer {    // 定义一个新的卷积层，输入blob为data，输出blob为conv1
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1    // 权值学习速率倍乘因子，1倍表示保持与全局参数一致
  }
  param {
    lr_mult: 2    // bias学习速率倍乘因子，是全局参数的2倍
  }
  convolution_param {    // 卷积计算参数
    num_output: 20       // 输出feature map数目为20，即有20个卷积核
    kernel_size: 5       // 卷积核尺寸，5 X 5
    stride: 1            // 卷积输出跳跃间隔，1表示连续输出，无跳跃
    weight_filler {      // 权值使用xavier填充器
      type: "xavier"
    }
    bias_filler {        // bias使用常数填充器，默认为0
      type: "constant"
    }
  }
}

</code></pre></div></div>

<p>可以看出，Caffe中的<code class="highlighter-rouge">lenet</code>网络对于卷积层的定义中，只指定了核的大小以及核的个数，上面为别为<code class="highlighter-rouge">5*5</code>和<code class="highlighter-rouge">20</code>。对于多通道图像，输出的<code class="highlighter-rouge">feature map</code>的个数只与卷积核的个数有关，而与通道数无关，比如对于一个单通道的图像进行卷积时，使用<code class="highlighter-rouge">10</code>个卷积核，得到<code class="highlighter-rouge">10</code>个<code class="highlighter-rouge">feature map</code>，当输入为<code class="highlighter-rouge">RGB</code>三通道时，输出仍为<code class="highlighter-rouge">10</code>个<code class="highlighter-rouge">feature map</code>，而不是<code class="highlighter-rouge">30</code>个，输出的个数依然是卷积核的个数。</p>

<h3 id="1-最简单的实现-嵌套循环">1. 最简单的实现: <em>嵌套循环</em></h3>

<p>参数定义 ：</p>

<ul>
  <li>
    <p>图片：宽度为width：<code class="highlighter-rouge">W</code>，高度为height：<code class="highlighter-rouge">H</code>，图片的通道数为<code class="highlighter-rouge">D</code>，一般目前都是<code class="highlighter-rouge">RGB</code>三通道的<code class="highlighter-rouge">D=3</code>，但是为了不失一般性用<code class="highlighter-rouge">D</code>表示。</p>
  </li>
  <li>
    <p>卷积核：卷积核的大小为<code class="highlighter-rouge">K * K</code>，每个通道的卷积核其实是不一样的，因此卷积核的大小其实也就是<code class="highlighter-rouge">D * K * K</code>，设卷积核的个数为<code class="highlighter-rouge">M</code>。</p>
  </li>
</ul>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for w in 1..W
  for h in 1..H
    for x in 1..K
      for y in 1..K
        for m in 1..M
          for d in 1..D
            output(w, h, m) += input(w+x, h+y, d) * filter(m, x, y, d)
          end
        end
      end
    end
  end
end
</code></pre></div></div>

<p>可以看到最内层的循环是针对通道数<code class="highlighter-rouge">D</code>的，说明对于<code class="highlighter-rouge">D</code>个通道而言，是在每个通道上分别执行二维卷积，然后将<code class="highlighter-rouge">D</code>个通道加起来，<code class="highlighter-rouge">output(w, h, m) += input(w+x, h+y, d) * filter(m, x, y, d)</code>中可以看到输出<code class="highlighter-rouge">output</code>已经没有了通道的信息，在有<code class="highlighter-rouge">padding</code>的情况下，能保持输出的特征图片大小和原来一样，总共为<code class="highlighter-rouge">M</code>个<code class="highlighter-rouge">W * H</code>的<code class="highlighter-rouge">feature map</code>。这也是可以理解的，对于一张彩色图像，有<code class="highlighter-rouge">RGB</code>三个通道，在计算卷积时，同一个位置的三个卷积核分别计算卷积后，它们是可以直接进行叠加的，因为在显示一张图时，每一个像素也是通过对<code class="highlighter-rouge">RGB</code>三个分量进行简单的叠加而生成的。</p>

<h3 id="2-caffe里面的计算方式">2. Caffe里面的计算方式</h3>

<p>先贴上JYQ大神的几张图：</p>

<center>
<img src="/blog/styles/images/jyq1.jpg" width="80%" height="80%" />
<img src="/blog/styles/images/jyq2.jpg" width="80%" height="80%" />
<img src="/blog/styles/images/jyq3.jpg" width="80%" height="80%" />
<img src="/blog/styles/images/jyq4.jpg" width="80%" height="80%" />
<img src="/blog/styles/images/jyq5.jpg" width="80%" height="80%" />
</center>

<p>核心思想是将图像数据和卷积核都平铺为二维的矩阵，然后进行矩阵相乘的计算。。先将图像数据根据<code class="highlighter-rouge">filter</code>的大小以及通道的大小来平铺，<code class="highlighter-rouge">Feature Matrix</code>的行数为<code class="highlighter-rouge">H*W</code>，列数为<code class="highlighter-rouge">C*K*K</code>，这里的<code class="highlighter-rouge">C</code>为通道数，相当于之前提到的<code class="highlighter-rouge">D</code>；然后将<code class="highlighter-rouge">filter</code>进行平铺，行数为<code class="highlighter-rouge">Cout</code>，列数为<code class="highlighter-rouge">C*K*K</code>，这里<code class="highlighter-rouge">Cout</code>为卷积核的个数，相当于之前提到的<code class="highlighter-rouge">M</code>；最后用<code class="highlighter-rouge">Filter Matrix</code>乘以<code class="highlighter-rouge">Feature Matrix</code>的转置，得到输出矩阵<code class="highlighter-rouge">Cout * (H * W)</code>，即<code class="highlighter-rouge">Cout</code>个<code class="highlighter-rouge">H*W</code>的<code class="highlighter-rouge">feature map</code>。</p>

<h3 id="3-im2col方法">3. im2col方法</h3>
<p>在Caffe的具体实现中，ConvolutionLayer的主要作用就是进行卷积操作，其中比较主要的函数就是im2col和col2im，为了方便理解，下图展示了caffe中具体的优化方法，图中上半部分是一个传统的卷积，下半部分是矩阵相乘的版本。</p>
<center>
<img src="/blog/styles/images/im2col.jpg" />
</center>

<p>图中可以看出来，图像大小为<code class="highlighter-rouge">3*3</code>，共有<code class="highlighter-rouge">3</code>个通道，卷积核的个数<code class="highlighter-rouge">M = 2</code>，但是由于通道数为<code class="highlighter-rouge">3</code>，所以实际上的核数量为<code class="highlighter-rouge">6</code>；从上图中可以看出来矩阵相乘的方式非常方便，并且矩阵计算还方便使用GPU加速。</p>

<h3 id="4-举个例子">4. 举个例子</h3>
<p><img src="/blog/styles/images/im2coljuli.png" alt="" /></p>

<h3 id="参考"><em>参考</em></h3>
<p>[1] <a href="http://blog.csdn.net/u014381600/article/details/60883856">http://blog.csdn.net/u014381600/article/details/60883856</a><br />
[2] <a href="http://blog.csdn.net/u014114990/article/details/51125776">http://blog.csdn.net/u014114990/article/details/51125776</a><br />
[3] <a href="https://www.zhihu.com/question/28385679">https://www.zhihu.com/question/28385679</a></p>

            </article>
        </div>
      </div>
    </div>
  </div>
</div>

    
    <footer class="footer" role="contentinfo">
	<div class="container">

	</div>
</footer>

<script src="/blog/styles/js/jquery.min.js"></script>
<script src="/blog/styles/js/bootstrap.min.js"></script>
<script src="/blog/styles/js/holder.min.js"></script>
<script src="/blog/styles/js/lessismore.js"></script>
<script src="/blog/styles/js/application.js"></script>
<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  </body>
</html>
